/llama.cpp/
/llama-server/
/onnx-server/
/onnxruntime-server/
oneinfer
nohup.out